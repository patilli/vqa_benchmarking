:mod:`vqa_benchmarking_backend.bottomupattention.models.bua.fast_rcnn`
======================================================================

.. py:module:: vqa_benchmarking_backend.bottomupattention.models.bua.fast_rcnn


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   vqa_benchmarking_backend.bottomupattention.models.bua.fast_rcnn.BUACaffeFastRCNNOutputs
   vqa_benchmarking_backend.bottomupattention.models.bua.fast_rcnn.BUACaffeFastRCNNOutputLayers
   vqa_benchmarking_backend.bottomupattention.models.bua.fast_rcnn.BUADetection2FastRCNNOutputs
   vqa_benchmarking_backend.bottomupattention.models.bua.fast_rcnn.BUADetectron2FastRCNNOutputLayers




Attributes
~~~~~~~~~~

.. autoapisummary::

   vqa_benchmarking_backend.bottomupattention.models.bua.fast_rcnn.logger


.. data:: logger
   

   Shape shorthand in this module:

       N: number of images in the minibatch
       R: number of ROIs, combined over all images, in the minibatch
       Ri: number of ROIs in image i
       K: number of foreground classes. E.g.,there are 80 foreground classes in COCO.

   Naming convention:

       deltas: refers to the 4-d (dx, dy, dw, dh) deltas that parameterize the box2box
       transform (see :class:`box_regression.Box2BoxTransform`).

       pred_class_logits: predicted class scores in [-inf, +inf]; use
           softmax(pred_class_logits) to estimate P(class).

       gt_classes: ground-truth classification labels in [0, K], where [0, K) represent
           foreground object classes and K represents the background class.

       pred_proposal_deltas: predicted box2box transform deltas for transforming proposals
           to detection box predictions.

       gt_proposal_deltas: ground-truth box2box transform deltas


.. class:: BUACaffeFastRCNNOutputs(box2box_transform, pred_class_logits, pred_proposal_deltas, proposals, smooth_l1_beta, image_scales, attr_on=False)


   Bases: :py:obj:`object`

   A class that stores information about outputs of a Fast R-CNN head.

   .. method:: fast_rcnn_inference(self, boxes, scores, image_shapes, image_scales, score_thresh, nms_thresh, topk_per_image)

      Call `fast_rcnn_inference_single_image` for all images.

      Args:
          boxes (list[Tensor]): A list of Tensors of predicted class-specific or class-agnostic
              boxes for each image. Element i has shape (Ri, K * 4) if doing
              class-specific regression, or (Ri, 4) if doing class-agnostic
              regression, where Ri is the number of predicted objects for image i.
              This is compatible with the output of :meth:`FastRCNNOutputs.predict_boxes`.
          scores (list[Tensor]): A list of Tensors of predicted class scores for each image.
              Element i has shape (Ri, K + 1), where Ri is the number of predicted objects
              for image i. Compatible with the output of :meth:`FastRCNNOutputs.predict_probs`.
          image_shapes (list[tuple]): A list of (width, height) tuples for each image in the batch.
          score_thresh (float): Only return detections with a confidence score exceeding this
              threshold.
          nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].
          topk_per_image (int): The number of top scoring detections to return. Set < 0 to return
              all detections.

      Returns:
          instances: (list[Instances]): A list of N instances, one for each image in the batch,
              that stores the topk most confidence detections.
          kept_indices: (list[Tensor]): A list of 1D tensor of length of N, each element indicates
              the corresponding boxes/scores index in [0, Ri) from the input, for image i.


   .. method:: fast_rcnn_inference_single_image(self, boxes, scores, image_shape, image_scale, score_thresh, nms_thresh, topk_per_image)

      Single-image inference. Return bounding-box detection results by thresholding
      on scores and applying non-maximum suppression (NMS).

      Args:
          Same as `fast_rcnn_inference`, but with boxes, scores, and image shapes
          per image.

      Returns:
          Same as `fast_rcnn_inference`, but for only one image.


   .. method:: predict_boxes(self)

      Returns:
      list[Tensor]: A list of Tensors of predicted class-specific or class-agnostic boxes
          for each image. Element i has shape (Ri, K * B) or (Ri, B), where Ri is
          the number of predicted objects for image i and B is the box dimension (4 or 5)


   .. method:: predict_probs(self)

      Returns:
      list[Tensor]: A list of Tensors of predicted class probabilities for each image.
          Element i has shape (Ri, K + 1), where Ri is the number of predicted objects
          for image i.


   .. method:: inference(self, score_thresh, nms_thresh, topk_per_image)

      Args:
          score_thresh (float): same as fast_rcnn_inference.
          nms_thresh (float): same as fast_rcnn_inference.
          topk_per_image (int): same as fast_rcnn_inference.
      Returns:
          list[Instances]: same as fast_rcnn_inference.
          list[Tensor]: same as fast_rcnn_inference.



.. class:: BUACaffeFastRCNNOutputLayers(input_size, num_classes, cls_agnostic_bbox_reg, box_dim=4, attr_on=False, num_attr_classes=401)


   Bases: :py:obj:`torch.nn.Module`

   Two linear layers for predicting Fast R-CNN outputs:
   (1) proposal-to-detection box regression deltas
   (2) classification scores

   .. method:: forward(self, x, proposal_boxes=None)



.. class:: BUADetection2FastRCNNOutputs(box2box_transform, pred_class_logits, pred_proposal_deltas, proposals, smooth_l1_beta, attr_on=False, pred_attribute_logits=None, num_attr_classes=400, gt_attributes=None)


   Bases: :py:obj:`detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputs`

   A class that stores information about outputs of a Fast R-CNN head.

   .. method:: _log_accuracy(self)

      Log the accuracy metrics to EventStorage.


   .. method:: softmax_cross_entropy_loss(self)

      Compute the softmax cross entropy loss for box classification.

      Returns:
          scalar Tensor


   .. method:: smooth_l1_loss(self)

      Compute the smooth L1 loss for box regression.

      Returns:
          scalar Tensor


   .. method:: attribute_loss(self)


   .. method:: losses(self)

      Compute the default losses for box head in Fast(er) R-CNN,
      with softmax cross entropy loss and smooth L1 loss.

      Returns:
          A dict of losses (scalar tensors) containing keys "loss_cls" and "loss_box_reg".


   .. method:: predict_boxes(self)

      Returns:
      list[Tensor]: A list of Tensors of predicted class-specific or class-agnostic boxes
          for each image. Element i has shape (Ri, K * B) or (Ri, B), where Ri is
          the number of predicted objects for image i and B is the box dimension (4 or 5)


   .. method:: predict_probs(self)

      Returns:
      list[Tensor]: A list of Tensors of predicted class probabilities for each image.
          Element i has shape (Ri, K + 1), where Ri is the number of predicted objects
          for image i.


   .. method:: inference(self, score_thresh, nms_thresh, topk_per_image)

      Args:
          score_thresh (float): same as fast_rcnn_inference.
          nms_thresh (float): same as fast_rcnn_inference.
          topk_per_image (int): same as fast_rcnn_inference.
      Returns:
          list[Instances]: same as fast_rcnn_inference.
          list[Tensor]: same as fast_rcnn_inference.



.. class:: BUADetectron2FastRCNNOutputLayers(input_size, num_classes, cls_agnostic_bbox_reg, box_dim=4, attr_on=False, num_attr_classes=400)


   Bases: :py:obj:`torch.nn.Module`

   Two linear layers for predicting Fast R-CNN outputs:
   (1) proposal-to-detection box regression deltas
   (2) classification scores

   .. method:: forward(self, x, proposal_boxes=None)



