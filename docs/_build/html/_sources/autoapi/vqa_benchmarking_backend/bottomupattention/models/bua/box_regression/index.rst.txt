:mod:`vqa_benchmarking_backend.bottomupattention.models.bua.box_regression`
===========================================================================

.. py:module:: vqa_benchmarking_backend.bottomupattention.models.bua.box_regression


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   vqa_benchmarking_backend.bottomupattention.models.bua.box_regression.BUABoxes
   vqa_benchmarking_backend.bottomupattention.models.bua.box_regression.BUABox2BoxTransform




.. class:: BUABoxes(tensor: torch.Tensor)


   Bases: :py:obj:`detectron2.structures.Boxes`

   This structure stores a list of boxes as a Nx4 torch.Tensor.
   It supports some common methods about boxes
   (`area`, `clip`, `nonempty`, etc),
   and also behaves like a Tensor
   (support indexing, `to(device)`, `.device`, and iteration over all boxes)

   Attributes:
       tensor: float matrix of Nx4.

   .. attribute:: BoxSizeType
      

      

   .. method:: clip(self, box_size: BoxSizeType) -> None

      NOTE: In order to be the same as bottom-up-attention network, we have
      defined the new clip function.

      Clip (in place) the boxes by limiting x coordinates to the range [0, width]
      and y coordinates to the range [0, height].

      Args:
          box_size (height, width): The clipping box's size.


   .. method:: nonempty(self, threshold: int = 0) -> torch.Tensor

      NOTE: In order to be the same as bottom-up-attention network, we have
      defined the new nonempty function.

      Find boxes that are non-empty.
      A box is considered empty, if either of its side is no larger than threshold.

      Returns:
          Tensor:
              a binary vector which represents whether each box is empty
              (False) or non-empty (True).


   .. method:: filter_boxes(self)


   .. method:: __getitem__(self, item: Union[int, slice, torch.BoolTensor]) -> detectron2.structures.Boxes

      Returns:
          BUABoxes: Create a new :class:`BUABoxes` by indexing.

      The following usage are allowed:
      1. `new_boxes = boxes[3]`: return a `Boxes` which contains only one box.
      2. `new_boxes = boxes[2:10]`: return a slice of boxes.
      3. `new_boxes = boxes[vector]`, where vector is a torch.BoolTensor
         with `length = len(boxes)`. Nonzero elements in the vector will be selected.

      Note that the returned Boxes might share storage with this Boxes,
      subject to Pytorch's indexing semantics.



.. class:: BUABox2BoxTransform(weights, scale_clamp=_DEFAULT_SCALE_CLAMP)


   Bases: :py:obj:`object`

   The box-to-box transform defined in R-CNN. The transformation is parameterized
   by 4 deltas: (dx, dy, dw, dh). The transformation scales the box's width and height
   by exp(dw), exp(dh) and shifts a box's center by the offset (dx * width, dy * height).

   .. method:: get_deltas(self, src_boxes, target_boxes)

      Get box regression transformation deltas (dx, dy, dw, dh) that can be used
      to transform the `src_boxes` into the `target_boxes`. That is, the relation
      ``target_boxes == self.apply_deltas(deltas, src_boxes)`` is true (unless
      any delta is too large and is clamped).

      Args:
          src_boxes (Tensor): source boxes, e.g., object proposals
          target_boxes (Tensor): target of the transformation, e.g., ground-truth
              boxes.


   .. method:: apply_deltas(self, deltas, boxes)

      Apply transformation `deltas` (dx, dy, dw, dh) to `boxes`.

      Args:
          deltas (Tensor): transformation deltas of shape (N, k*4), where k >= 1.
              deltas[i] represents k potentially different class-specific
              box transformations for the single box boxes[i].
          boxes (Tensor): boxes to transform, of shape (N, 4)



