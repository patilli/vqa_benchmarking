:mod:`vqa_benchmarking_backend.bottomupattention.models.bua.rcnn`
=================================================================

.. py:module:: vqa_benchmarking_backend.bottomupattention.models.bua.rcnn


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   vqa_benchmarking_backend.bottomupattention.models.bua.rcnn.GeneralizedBUARCNN




.. class:: GeneralizedBUARCNN(cfg)


   Bases: :py:obj:`torch.nn.Module`

   Generalized R-CNN. Any models that contains the following three components:
   1. Per-image feature extraction (aka backbone)
   2. Region proposal generation
   3. Per-region feature extraction and prediction

   .. method:: forward(self, batched_inputs)

      Args:
          batched_inputs: a list, batched outputs of :class:`DatasetMapper` .
              Each item in the list contains the inputs for one image.
              For now, each item in the list is a dict that contains:

              * image: Tensor, image in (C, H, W) format.
              * instances (optional): groundtruth :class:`Instances`
              * proposals (optional): :class:`Instances`, precomputed proposals.

              Other information that's included in the original dicts, such as:

              * "height", "width" (int): the output resolution of the model, used in inference.
                  See :meth:`postprocess` for details.

      Returns:
          list[dict]:
              Each dict is the output for one input image.
              The dict contains one key "instances" whose value is a :class:`Instances`.
              The :class:`Instances` object has the following keys:
                  "pred_boxes", "pred_classes", "scores", "pred_masks", "pred_keypoints"


   .. method:: inference(self, batched_inputs, detected_instances=None, do_postprocess=True)

      Run inference on the given inputs.

      Args:
          batched_inputs (list[dict]): same as in :meth:`forward`
          detected_instances (None or list[Instances]): if not None, it
              contains an `Instances` object per image. The `Instances`
              object contains "pred_boxes" and "pred_classes" which are
              known boxes in the image.
              The inference will then skip the detection of bounding boxes,
              and only predict other per-ROI outputs.
          do_postprocess (bool): whether to apply post-processing on the outputs.

      Returns:
          same as in :meth:`forward`.


   .. method:: preprocess_image(self, batched_inputs)

      Normalize, pad and batch the input images.



