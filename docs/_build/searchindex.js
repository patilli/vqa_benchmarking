Search.setIndex({docnames:["autoapi/index","autoapi/vqa_benchmarking_backend/datasets/CLEVRDataset/index","autoapi/vqa_benchmarking_backend/datasets/GQADataset/index","autoapi/vqa_benchmarking_backend/datasets/TextVQADataset/index","autoapi/vqa_benchmarking_backend/datasets/VQADataset/index","autoapi/vqa_benchmarking_backend/datasets/dataset/index","autoapi/vqa_benchmarking_backend/datasets/index","autoapi/vqa_benchmarking_backend/datasets/tests/clever_dataset_test/index","autoapi/vqa_benchmarking_backend/datasets/tests/gqa_dataset_test/index","autoapi/vqa_benchmarking_backend/datasets/tests/index","autoapi/vqa_benchmarking_backend/datasets/tests/ok_vqa_test/index","autoapi/vqa_benchmarking_backend/datasets/tests/text_vqa/index","autoapi/vqa_benchmarking_backend/metrics/bias/index","autoapi/vqa_benchmarking_backend/metrics/index","autoapi/vqa_benchmarking_backend/metrics/metrics/index","autoapi/vqa_benchmarking_backend/metrics/model_info/index","autoapi/vqa_benchmarking_backend/metrics/robustness/index","autoapi/vqa_benchmarking_backend/metrics/sear/index","autoapi/vqa_benchmarking_backend/metrics/uncertainty/index","autoapi/vqa_benchmarking_backend/tokenizers/index","autoapi/vqa_benchmarking_backend/tokenizers/vqatokenizer/index","autoapi/vqa_benchmarking_backend/utils/index","autoapi/vqa_benchmarking_backend/utils/vocab/index","buildDataset","evalMetrics","index","installation","modelAdapter","started","useDatasets"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":3,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":2,"sphinx.domains.rst":2,"sphinx.domains.std":1,sphinx:56},filenames:["autoapi/index.rst","autoapi/vqa_benchmarking_backend/datasets/CLEVRDataset/index.rst","autoapi/vqa_benchmarking_backend/datasets/GQADataset/index.rst","autoapi/vqa_benchmarking_backend/datasets/TextVQADataset/index.rst","autoapi/vqa_benchmarking_backend/datasets/VQADataset/index.rst","autoapi/vqa_benchmarking_backend/datasets/dataset/index.rst","autoapi/vqa_benchmarking_backend/datasets/index.rst","autoapi/vqa_benchmarking_backend/datasets/tests/clever_dataset_test/index.rst","autoapi/vqa_benchmarking_backend/datasets/tests/gqa_dataset_test/index.rst","autoapi/vqa_benchmarking_backend/datasets/tests/index.rst","autoapi/vqa_benchmarking_backend/datasets/tests/ok_vqa_test/index.rst","autoapi/vqa_benchmarking_backend/datasets/tests/text_vqa/index.rst","autoapi/vqa_benchmarking_backend/metrics/bias/index.rst","autoapi/vqa_benchmarking_backend/metrics/index.rst","autoapi/vqa_benchmarking_backend/metrics/metrics/index.rst","autoapi/vqa_benchmarking_backend/metrics/model_info/index.rst","autoapi/vqa_benchmarking_backend/metrics/robustness/index.rst","autoapi/vqa_benchmarking_backend/metrics/sear/index.rst","autoapi/vqa_benchmarking_backend/metrics/uncertainty/index.rst","autoapi/vqa_benchmarking_backend/tokenizers/index.rst","autoapi/vqa_benchmarking_backend/tokenizers/vqatokenizer/index.rst","autoapi/vqa_benchmarking_backend/utils/index.rst","autoapi/vqa_benchmarking_backend/utils/vocab/index.rst","buildDataset.rst","evalMetrics.rst","index.rst","installation.rst","modelAdapter.rst","started.rst","useDatasets.rst"],objects:{"vqa_benchmarking_backend.datasets":{CLEVRDataset:[1,0,0,"-"],GQADataset:[2,0,0,"-"],TextVQADataset:[3,0,0,"-"],VQADataset:[4,0,0,"-"],dataset:[5,0,0,"-"],tests:[9,0,0,"-"]},"vqa_benchmarking_backend.datasets.CLEVRDataset":{CLEVRDataSample:[1,1,1,""],CLEVRDataset:[1,1,1,""],load_img:[1,3,1,""],load_img_feats:[1,3,1,""],preprocess_question:[1,3,1,""]},"vqa_benchmarking_backend.datasets.CLEVRDataset.CLEVRDataSample":{__str__:[1,2,1,""],image:[1,2,1,""],question:[1,2,1,""],question_token_ids:[1,2,1,""],question_tokenized:[1,2,1,""]},"vqa_benchmarking_backend.datasets.CLEVRDataset.CLEVRDataset":{__getitem__:[1,2,1,""],__len__:[1,2,1,""],_load_data:[1,2,1,""],class_idx_to_answer:[1,2,1,""],get_name:[1,2,1,""],index_to_question_id:[1,2,1,""],label_from_class:[1,2,1,""],word_in_vocab:[1,2,1,""]},"vqa_benchmarking_backend.datasets.GQADataset":{GQADataSample:[2,1,1,""],GQADataset:[2,1,1,""],load_img:[2,3,1,""],load_img_feats:[2,3,1,""],preprocess_question:[2,3,1,""]},"vqa_benchmarking_backend.datasets.GQADataset.GQADataSample":{__str__:[2,2,1,""],image:[2,2,1,""],question_tokenized:[2,2,1,""]},"vqa_benchmarking_backend.datasets.GQADataset.GQADataset":{__getitem__:[2,2,1,""],__len__:[2,2,1,""],_load_data:[2,2,1,""],class_idx_to_answer:[2,2,1,""],get_name:[2,2,1,""],index_to_question_id:[2,2,1,""],label_from_class:[2,2,1,""],word_in_vocab:[2,2,1,""]},"vqa_benchmarking_backend.datasets.TextVQADataset":{TextVQADataSample:[3,1,1,""],TextVQADataset:[3,1,1,""],answer_score:[3,3,1,""],load_img:[3,3,1,""],load_img_feats:[3,3,1,""],preprocess_question:[3,3,1,""]},"vqa_benchmarking_backend.datasets.TextVQADataset.TextVQADataSample":{__str__:[3,2,1,""],image:[3,2,1,""],question:[3,2,1,""],question_tokenized:[3,2,1,""]},"vqa_benchmarking_backend.datasets.TextVQADataset.TextVQADataset":{__getitem__:[3,2,1,""],__len__:[3,2,1,""],_load_data:[3,2,1,""],class_idx_to_answer:[3,2,1,""],get_name:[3,2,1,""],index_to_question_id:[3,2,1,""],label_from_class:[3,2,1,""],word_in_vocab:[3,2,1,""]},"vqa_benchmarking_backend.datasets.VQADataset":{VQADataSample:[4,1,1,""],VQADataset:[4,1,1,""],answer_score:[4,3,1,""],load_img:[4,3,1,""],load_img_feats:[4,3,1,""],preprocess_answer:[4,3,1,""],preprocess_question:[4,3,1,""]},"vqa_benchmarking_backend.datasets.VQADataset.VQADataSample":{image:[4,2,1,""],question:[4,2,1,""],question_tokenized:[4,2,1,""]},"vqa_benchmarking_backend.datasets.VQADataset.VQADataset":{__getitem__:[4,2,1,""],__len__:[4,2,1,""],_load_data:[4,2,1,""],class_idx_to_answer:[4,2,1,""],get_name:[4,2,1,""]},"vqa_benchmarking_backend.datasets.dataset":{DataSample:[5,1,1,""],DatasetModelAdapter:[5,1,1,""],DiagnosticDataset:[5,1,1,""]},"vqa_benchmarking_backend.datasets.dataset.DataSample":{answers:[5,2,1,""],image:[5,2,1,""],image_features:[5,2,1,""],image_id:[5,2,1,""],question:[5,2,1,""],question_features:[5,2,1,""],question_id:[5,2,1,""],question_tokenized:[5,2,1,""]},"vqa_benchmarking_backend.datasets.dataset.DatasetModelAdapter":{_forward:[5,2,1,""],eval:[5,2,1,""],forward:[5,2,1,""],get_image_embedding:[5,2,1,""],get_name:[5,2,1,""],get_output_size:[5,2,1,""],get_question_embedding:[5,2,1,""],get_torch_module:[5,2,1,""],train:[5,2,1,""]},"vqa_benchmarking_backend.datasets.dataset.DiagnosticDataset":{__getitem__:[5,2,1,""],__len__:[5,2,1,""],class_idx_to_answer:[5,2,1,""],get_name:[5,2,1,""]},"vqa_benchmarking_backend.datasets.tests":{clever_dataset_test:[7,0,0,"-"],gqa_dataset_test:[8,0,0,"-"],ok_vqa_test:[10,0,0,"-"],text_vqa:[11,0,0,"-"]},"vqa_benchmarking_backend.datasets.tests.clever_dataset_test":{gqa_dataset:[7,4,1,""],img_dir:[7,4,1,""],qsts_path:[7,4,1,""],test:[7,4,1,""]},"vqa_benchmarking_backend.datasets.tests.gqa_dataset_test":{gqa_dataset:[8,4,1,""],img_dir:[8,4,1,""],qsts_path:[8,4,1,""],test:[8,4,1,""]},"vqa_benchmarking_backend.datasets.tests.ok_vqa_test":{anno_path:[10,4,1,""],img_dir:[10,4,1,""],okVqa_dataset:[10,4,1,""],qsts_path:[10,4,1,""],test:[10,4,1,""]},"vqa_benchmarking_backend.datasets.tests.text_vqa":{img_dir:[11,4,1,""],qsts_path:[11,4,1,""],test:[11,4,1,""],textVqa_dataset:[11,4,1,""]},"vqa_benchmarking_backend.metrics":{bias:[12,0,0,"-"],metrics:[14,0,0,"-"],model_info:[15,0,0,"-"],robustness:[16,0,0,"-"],sear:[17,0,0,"-"],uncertainty:[18,0,0,"-"]},"vqa_benchmarking_backend.metrics.bias":{_extract_subjects_and_objects_from_text:[12,3,1,""],_questions_different:[12,3,1,""],eval_bias:[12,3,1,""],inputs_for_image_bias_featurespace:[12,3,1,""],inputs_for_image_bias_wordspace:[12,3,1,""],inputs_for_question_bias_featurespace:[12,3,1,""],inputs_for_question_bias_imagespace:[12,3,1,""],nlp:[12,4,1,""]},"vqa_benchmarking_backend.metrics.metrics":{_get_db_connection:[14,3,1,""],_get_img_feature_range:[14,3,1,""],_get_question_feature_range:[14,3,1,""],_reduce_max:[14,3,1,""],_reduce_min:[14,3,1,""],_write_class_answer_mapping:[14,3,1,""],_write_qid_question_mapping:[14,3,1,""],_write_table:[14,3,1,""],calculate_metrics:[14,3,1,""]},"vqa_benchmarking_backend.metrics.model_info":{model_info:[15,3,1,""]},"vqa_benchmarking_backend.metrics.robustness":{eval_robustness:[16,3,1,""],inputs_for_image_robustness_featurespace:[16,3,1,""],inputs_for_image_robustness_imagespace:[16,3,1,""],inputs_for_question_robustness_featurespace:[16,3,1,""],inputs_for_question_robustness_wordspace:[16,3,1,""]},"vqa_benchmarking_backend.metrics.sear":{_apply_SEAR_1:[17,3,1,""],_apply_SEAR_2:[17,3,1,""],_apply_SEAR_3:[17,3,1,""],_apply_SEAR_4:[17,3,1,""],eval_sears:[17,3,1,""],inputs_for_question_sears:[17,3,1,""]},"vqa_benchmarking_backend.metrics.uncertainty":{certainty:[18,3,1,""]},"vqa_benchmarking_backend.tokenizers":{vqatokenizer:[20,0,0,"-"]},"vqa_benchmarking_backend.tokenizers.vqatokenizer":{articles:[20,4,1,""],comma_strip:[20,4,1,""],contractions:[20,4,1,""],manual_map:[20,4,1,""],period_strip:[20,4,1,""],process_digit_article:[20,3,1,""],process_punctuation:[20,3,1,""],punct:[20,4,1,""]},"vqa_benchmarking_backend.utils":{vocab:[22,0,0,"-"]},"vqa_benchmarking_backend.utils.vocab":{Vocabulary:[22,1,1,""]},"vqa_benchmarking_backend.utils.vocab.Vocabulary":{__len__:[22,2,1,""],add_token:[22,2,1,""],exists:[22,2,1,""],itos:[22,2,1,""],load:[22,2,1,""],save:[22,2,1,""],stoi:[22,2,1,""]},vqa_benchmarking_backend:{datasets:[6,0,0,"-"],metrics:[13,0,0,"-"],tokenizers:[19,0,0,"-"],utils:[21,0,0,"-"]}},objnames:{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","method","Python method"],"3":["py","function","Python function"],"4":["py","data","Python data"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method","3":"py:function","4":"py:data"},terms:{"025":16,"100":[12,16,27],"12345":[1,4,16],"1_test":11,"1st":17,"2nd":17,"500":14,"8080":26,"abstract":5,"class":[12,16,18,23,27],"float":[1,2,3,4,5,12,16,18,23],"function":[5,23,27],"import":[5,23,24,27,29],"int":[1,2,3,4,5,12,14,15,16,18,22,23,27],"long":27,"new":[25,28],"return":[2,5,12,14,15,16,17,18,23,27],"super":23,"true":[14,15,17,27],The:[23,24,26],These:29,Use:[25,28],__getitem__:[1,2,3,4,5,23],__init__:[23,27],__len__:[1,2,3,4,5,22,23],__str__:[1,2,3],_apply_sear_1:17,_apply_sear_2:17,_apply_sear_3:17,_apply_sear_4:17,_extract_subjects_and_objects_from_text:12,_forward:[5,27],_get_db_connect:14,_get_img_feature_rang:14,_get_question_feature_rang:14,_image_path:[23,27],_img:23,_img_feat:23,_load_data:[1,2,3,4,23],_question:23,_questions_differ:12,_reduce_max:14,_reduce_min:14,_write_class_answer_map:14,_write_qid_question_map:14,_write_t:14,a_vocab:23,accuraci:[14,24],across:14,adapt:[14,16,18,24,25,26,28],add:23,add_token:[22,23],adding:26,addit:16,all:[23,24,29],all_indic:29,also:12,amount:24,analyz:26,ani:[26,29],anno_path:10,annotation_fil:4,ans_str:24,answer:[1,2,3,4,5,12,17,23],answer_fil:[4,29],answer_scor:[3,4],answer_vocab:23,api:[16,25],append:23,appli:17,applic:[17,26],arg:[12,14,16,17],articl:20,assign:[5,27],auto:0,autoapi:0,averag:24,backend:25,base:[1,2,3,4,5,20],batch_first:27,becaus:16,benchmark:[7,8,10,11,23],bert:16,best:[12,16,18],between:14,bia:13,block:[23,24],bool:[1,2,3,12,14,15,22,23],bottomupattent:27,box:29,brief:23,bua:27,build:25,built:29,bundl:26,cach:[23,27],caff:27,calcul:[3,4,5,24,27],calculate_metr:[14,24],call:24,can:29,carlo:[18,24],certainti:18,chang:[16,17,18,26],check:12,choic:14,ckpt_file:27,class_idx:[1,2,3,4,5,23],class_idx_to_answ:[1,2,3,4,5,23],class_index:[1,2,3,23],classifi:23,classmethod:22,clever_dataset_test:[6,9],clevr:[7,29],clevr_dataset:29,clevr_img_dir:29,clevr_qsts_path:29,clevr_v1:7,clevr_val_quest:7,clevrdatasampl:1,clevrdataset:[6,29],clone:26,cls:22,code:[20,23,24],color:16,column:14,com:[20,26],come:23,comma_strip:20,comparison:12,config:27,connect:[5,14,27],consid:26,contain:[0,12,23,24],contract:20,correspond:[17,23],could:[5,24,27],count:15,cpu:27,creat:[0,12,16,17,28],cuda:27,current:12,current_sampl:[12,16,17],data:[5,14,22,26,27,28],databas:26,datasampl:[1,2,3,4,5,12,16,17,18,23,27],dataset:[12,14,16,17,18,24,25,26,28],dataset_fract:[1,4,29],datasetmodeladapt:[5,14,16,18,27],def:[23,27],defin:24,delet:16,depend:[3,4,26],desir:23,dev:26,devic:[5,27],diagnost:28,diagnosticdataset:[1,2,3,4,5,12,14,16,17,18,23,24],dict:[1,2,3,4,5,12,14,16,17,18,22,23,24],dictionari:[17,23],differ:18,dim:[12,27],dimens:12,dir:24,directori:[23,24,26],doabl:16,doc:16,document:[0,23],doe:16,don:[12,16],drawn:12,dropout:18,dtype:27,each:23,either:17,els:[23,27],emb:27,embed:[5,27],entri:[17,23],entropi:18,equal:12,equival:17,eval:5,eval_bia:12,eval_robust:16,eval_sear:17,evalu:[25,28],evalut:[12,16,17],exampl:[24,29],exemplari:23,exist:[22,23,27],extract:27,extract_feat_in_memori:27,fals:[1,2,3,4,17],fasttext:16,featur:[5,12,14,16,23,27],feature_dim:14,few:29,field:[5,27],file:[23,24,27],flip:17,floattensor:[1,2,3,4,5,12,14,16,17,27],follow:[23,24,29],format:[23,29],forward:[5,27],fraction:[12,16,18],from:[5,12,16,18,23,24,27,29],full:27,gaussian:16,gaussian_mean:16,gaussian_vari:16,gener:[0,12,16,17],get:[16,25,26],get_image_embed:[5,27],get_nam:[1,2,3,4,5,23,27],get_output_s:[5,27],get_question_embed:[5,27],get_torch_modul:[5,27],git:26,github:[20,26],given:[3,4,24],gpu_id:27,gqa:[8,24,29],gqa_dataset:[7,8,29],gqa_dataset_odd_al:29,gqa_dataset_odd_head:29,gqa_dataset_odd_tail:29,gqa_dataset_test:[6,9],gqa_ood_testdev_al:29,gqa_ood_testdev_head:29,gqa_ood_testdev_tail:29,gqadatasampl:2,gqadataset:[6,24,29],grammat:16,have:[3,4,16],head:29,here:[5,27],home:[7,8,10,11],hot:26,how:[18,23,24],html:16,http:[16,20,26],human:[3,4],idea:16,idx2an:[1,2,3,23,24,29],idx:24,iid:23,imag:[1,2,3,4,5,7,8,10,11,12,16,23,24],image_bias_featurespac:14,image_bias_wordspac:[14,24],image_feat_path:[1,2,3,4,5],image_featur:[5,27],image_id:[1,2,3,4,5,23],image_path:[1,2,3,4,5,23],image_robustness_featurespac:[14,24],image_robustness_imagespac:[14,24],image_transform:[1,2,3,4,5],imageid:23,img_dir:[1,2,3,4,7,8,10,11,23,24,29],img_feat:27,img_feat_cfg:27,img_feat_dim:12,img_feat_dir:[1,2,3,4,24,29],img_feat_extractor:27,index:[1,2,3,4,5,17,22,23],index_to_question_id:[1,2,3,23],inform:[17,23],inherit:[5,23,27],inhert:24,init:25,input:[12,16,17],inputs_for_image_bias_featurespac:[12,16],inputs_for_image_bias_wordspac:[12,16],inputs_for_image_robustness_featurespac:16,inputs_for_image_robustness_imagespac:16,inputs_for_question_bias_featurespac:[12,16],inputs_for_question_bias_imagespac:[12,16],inputs_for_question_robustness_featurespac:16,inputs_for_question_robustness_wordspac:16,inputs_for_question_sear:17,insert:[16,29],insid:[5,27],instal:25,instanti:24,instead:[5,27],integr:[25,26,28],intend:[5,27],interfac:25,intext:20,isinst:[23,27],iter:23,ito:[22,23],join:23,jpg:23,json:[8,10,11,22,23,24],kei:23,label:12,label_from_class:[1,2,3,23],languag:23,latest:26,len:[16,23],length:[16,17],like:[23,24],linux:26,list:[1,2,3,4,5,12,14,16,17,23,24,27],load:[22,23,27,29],load_idx_map:24,load_img:[1,2,3,4,23],load_img_feat:[1,2,3,4],load_img_featur:[1,2,3,4],load_state_dict:27,localhost:26,localvar:16,logit:[5,27],longtensor:[1,27],look:24,maco:26,make:[5,27],manual_map:20,map:[12,16,18,23],map_loc:27,match:23,max_edits_per_sampl:16,max_img_feat:12,max_img_feat_v:12,max_question_feat_v:12,max_sampl:14,max_token:[12,14],maximum:[12,14],mayb:16,mean:[12,16,17],meaning:16,measur:[12,18],method:[5,27],metric:[25,28],metric_nam:14,might:16,milvlg:20,min_img_feat:12,min_img_feat_v:12,min_question_feat_v:12,min_token:[12,14],minif:26,minimum:[12,14],model:[5,12,16,17,24,25,26,28],model_adapt:24,model_info:13,modifi:[5,27],modul:27,mont:[18,24],more:16,move:[5,27],mscoco_val2014_annot:10,my_datasampl:23,mydatasampl:23,mydataset:23,mymodel:27,mymodeladapt:27,n_class:27,name:[2,4,23,24,27,29],natur:23,ndarrai:[1,2,3,4,5,23],need:[23,24,27],net:15,next:23,nlp:12,node:26,nois:16,noise_typ:16,none:[1,2,3,4,5,17,22,23,27],normal:[12,16],note:[5,16,17,27],npm:26,num_human:[3,4],num_it:18,num_sampl:14,number:[3,4,12,15,24,27],numpi:[1,2,3,4,5],object:[12,23],often:18,ok_vqa_anno_path:29,ok_vqa_imgs_path:29,ok_vqa_qsts_path:29,ok_vqa_test:[6,9],okvqa_dataset:[10,29],onc:15,onli:15,only_train:15,ood:29,open:23,openended_mscoco_val2014_:10,openvqa:20,order:16,org:16,origin:23,original_class_predict:[12,16,17],ouput:24,our:[24,29],out:29,output:[5,16,17,24,27],output_dir:24,output_path:[14,24],overlap:12,overview:23,overwrit:[5,14,27],own:24,pad_sequ:27,page:0,paramet:[15,24],pass:24,path:[1,2,3,4,22,23,24,29],patilli:26,pepper:16,per:[12,14,16,17],perform:24,period_strip:20,permut:16,pip:26,poisson:16,predict:[12,16,17,18,27],predicted_class:17,preprocess:23,preprocess_answ:4,preprocess_quest:[1,2,3,4,23],prob:27,probabl:[5,12,16,17,27],process_digit_articl:20,process_punctu:20,product:26,properti:[1,2,3,4,5,23],provid:[23,26],punct:20,python:25,pytorch:[26,29],q_a:12,q_b:12,q_feat:27,q_vocab:23,qid:23,qid_to_sampl:23,qsts_path:[7,8,10,11,24,29],que:23,question:[1,2,3,4,5,7,8,10,11,12,17,23,24,27],question_bias_featurespac:14,question_bias_imagespac:[14,24],question_featur:[5,27],question_fil:[1,2,3,4,23,24,29],question_id:[1,2,3,4,5,23],question_postag:17,question_robustness_featurespac:[14,24],question_robustness_wordspac:14,question_token:[1,2,3,4,5,17,23,27],question_token_id:[1,27],question_vocab:23,r101:27,random:[12,16],random_se:[1,4],randomli:12,rang:[12,18],rank:18,refer:[24,25],relev:23,reload:26,replac:[12,16],report:26,repositori:26,repres:23,requir:[23,25,29],requires_grad:15,reset:23,respect:24,result:5,rewritten:23,robust:13,run:[26,27],safe:16,salt:16,salt_pepper_amount:16,salt_vs_pepper_ratio:16,same:[3,4,12,18,29],sampl:[5,12,18,27,28],save:22,scikit:16,score:[3,4,12,16,18],script:24,sear:[13,14,24],sear_4:17,sear_input:17,sear_predict:17,seed:16,self:[1,2,3,4,5,22,23,27],semant:[12,17],sequenc:27,serv:26,server:26,set:12,setter:23,setup:27,share:15,should:[16,23,24],simpl:12,simtech:[7,8,10,11],sinc:23,skimag:16,softmax:27,space:[5,12,16,17,27],speckl:16,speckle_mean:16,speckle_vari:16,sphinx:0,split:[23,27,29],sqlite3:[14,26],stabl:16,start:[24,25],start_sampl:14,state_dict:27,std:16,step:25,stoi:[22,23,27],store:[23,26],str:[1,2,3,4,5,12,14,16,17,22,23,27],string:23,structur:29,sub:16,subject:12,subword:16,sure:[5,27],synonym:16,tail:29,tensor:[12,14,27],test:[6,12,24],test_imag:11,testdev_balanced_quest:8,text:[11,12],text_vqa:[6,9],text_vqa_imgs_path:29,text_vqa_qsts_path:29,textvqa:29,textvqa_0:11,textvqa_dataset:[11,29],textvqadatasampl:3,textvqadataset:[6,29],than:16,thei:[5,27],them:[5,27],thi:[0,5,20,23,27],though:16,thtough:27,tillipl:[7,8,10,11],time:18,token:[22,23,27],torch:[1,2,3,4,5,12,14,15,16,17,27],torchvis:26,tornado:26,total:[12,15,16,18],toward:12,tqdm:23,train:5,transform:[1,2,3,4],trial:[12,14,16,18,24],tupl:[1,2,3,4,12,14,16,17,18,23],two:23,type:[16,17,23,27],typo:16,uncertainti:[13,14,24],union:[1,2,3,4,5,17,22,23],unk:27,unneccessari:16,updat:23,used:[15,29],users0:[7,8,10,11],using:[5,27,29],util:[1,2,3,4,5,16,23],val2014:10,val:7,val_annotation_fil:[4,29],val_question_fil:[4,29],valu:[12,14,17],vanilla:29,vector:12,version:26,view:26,vocab:[1,2,3,4,16,21,23,27],vocabulari:[1,2,3,4,22,23,27],vqa2:29,vqa:[3,4,7,8,10,11,29],vqa_benchmark:26,vqa_benchmarking_backend:[23,24,26,29],vqa_model:27,vqadatasampl:4,vqadataset:[6,29],vqatoken:19,vqav2_anno_path:29,vqav2_dataset:29,vqav2_img_dir:29,vqav2_qsts_path:29,vue:26,web:25,what:16,when:[5,16,27],where:[12,16,17],without:27,word:[1,2,3,16,22,23],word_in_vocab:[1,2,3,23],write:[25,28],written:26,yaml:27,you:24,your:[5,23,24,27]},titles:["API Reference","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.CLEVRDataset</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.GQADataset</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.TextVQADataset</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.VQADataset</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.dataset</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.tests.clever_dataset_test</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.tests.gqa_dataset_test</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.tests</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.tests.ok_vqa_test</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.datasets.tests.text_vqa</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.metrics.bias</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.metrics</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.metrics.metrics</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.metrics.model_info</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.metrics.robustness</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.metrics.sear</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.metrics.uncertainty</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.tokenizers</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.tokenizers.vqatokenizer</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.utils</span></code>","<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">vqa_benchmarking_backend.utils.vocab</span></code>","Integrate new Datasets","Evaluate Metrics","Welcome to VQA Benchmarking\u2019s documentation!","Installation","Write a Model Adapter","Getting Started","Use integrated Datasets"],titleterms:{"class":[1,2,3,4,5,22],"function":[1,2,3,4,12,14,15,16,17,18,20],"new":23,Use:29,adapt:27,api:0,attribut:[12,20],backend:26,benchmark:25,bia:12,build:26,clever_dataset_test:7,clevrdataset:1,content:[1,2,3,4,5,7,8,10,11,12,14,15,16,17,18,20,22],creat:23,data:23,dataset:[1,2,3,4,5,6,7,8,9,10,11,23,29],diagnost:23,document:25,evalu:24,get:28,gqa_dataset_test:8,gqadataset:2,init:26,instal:26,integr:[23,29],interfac:26,metric:[12,13,14,15,16,17,18,24],model:27,model_info:15,modul:[1,2,3,4,5,7,8,10,11,12,14,15,16,17,18,20,22],ok_vqa_test:10,python:26,refer:0,requir:26,robust:16,sampl:23,sear:17,start:28,step:26,submodul:[6,9,13,19,21],subpackag:6,test:[7,8,9,10,11],text_vqa:11,textvqadataset:3,token:[19,20],uncertainti:18,util:[21,22],vocab:22,vqa:25,vqa_benchmarking_backend:[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],vqadataset:4,vqatoken:20,web:26,welcom:25,write:27}})